### The project is under active development, any functions might be changed at anytime.

# Baconian:  Boosting the model-based reinforcement learning 
[![Build Status](https://travis-ci.com/Lukeeeeee/baconian.svg?branch=master)](https://travis-ci.com/Lukeeeeee/baconian)
[![Documentation Status](https://readthedocs.org/projects/baconian-public/badge/?version=latest)](https://baconian-public.readthedocs.io/en/latest/?badge=latest)

Baconian [beËˆkonin] is a toolbox for model-based reinforcement learning with user-friendly experiment setting-up, logging 
and visualization modules developed by [CAP](http://cap.scse.ntu.edu.sg/). We aim to develop a flexible, re-usable and 
modularized framework that can allow the user's to easily set-up a model-based rl experiments by reuse modules we 
offered.

![CAP](https://user-images.githubusercontent.com/9161548/40165577-eff023c4-59ee-11e8-8bf5-508325a23baa.png)

### Release news:
- 2019.3.24 Release the v0.1.3 add GP dynamics, fix some bugs.
- 2019.3.23 Release the v0.1.2, add linear dynamics, iLQR, LQR methods.

For previous release news, please refer to [old news](./old_news.md) 

### Documentation
Documentation is available at http://baconian.withcap.org (hosted by CAP server)  
or https://baconian-public.readthedocs.io/en/latest/ (host by Read the Docs)
(the documentations writing is still undergoing)

### Todo

- [ ] Visualization module
- [ ] State-of-art model-based algorithms: PILCO, GPS etc.
- [ ] Latent-space method supporting.
- [ ] Benchmark tests on multiple tasks

### Acknowledgement 
Thanks to the following open-source projects:

- garage: https://github.com/rlworkgroup/garage
- rllab: https://github.com/rll/rllab
- baselines: https://github.com/openai/baselines
- gym: https://github.com/openai/gym
- trpo: https://github.com/pat-coady/trpo

### Report an issue 
If you find any bugs on issues during your usage of the package, please open an issue or send an email to me 
(linsen001@e.ntu.edu.sg) with detail information. I appreciate your helps!